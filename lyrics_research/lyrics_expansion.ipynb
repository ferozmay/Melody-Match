{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Work with lyrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Make lyrics inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lyrics in BOW format:\n",
    "# !cd data\n",
    "# !wget http://millionsongdataset.com/sites/default/files/AdditionalFiles/mxm_dataset_train.txt.zip\n",
    "# !wget http://millionsongdataset.com/sites/default/files/AdditionalFiles/mxm_dataset_test.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyrics_inverted_index saved as pickle at data/lyrics_inverted_word.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# LOAD DICTS\n",
    "lyrics_test_path = 'data/mxm_dataset_test.txt'\n",
    "lyrics_train_path = 'data/mxm_dataset_train.txt'\n",
    "\n",
    "# Output\n",
    "lyrics_all_words_path = 'data/lyrics_all_words.txt'\n",
    "lyrics_inverted_index_path = 'data/lyrics_inverted_idx.pkl'\n",
    "\n",
    "def read_lyrics(lyrics_train_path, lyrics_test_path):\n",
    "    '''\n",
    "    Combine the lyrics from the train and test files into a dictionary\n",
    "    \n",
    "    Returns: a dictionary with the format {'word_idx': {'track_id': counts}} \n",
    "    '''\n",
    "    lyrics_dict = {}\n",
    "\n",
    "    # Read the lyrics from the train and test files\n",
    "    for lyrics_path in [lyrics_train_path, lyrics_test_path]:\n",
    "        with open(lyrics_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#'):\n",
    "                    continue # It is a comment\n",
    "                if line.startswith('%'):\n",
    "                    # List of all words\n",
    "                    all_words = line[1:].split(',')\n",
    "                elif line.startswith('TR'):\n",
    "                    line = line.split(',')\n",
    "                    track_id = line[0]\n",
    "                    word_dict = {int(id): int(freq) for id_freq in line[2:] for id, freq in [id_freq.split(':')]}\n",
    "                    lyrics_dict[track_id] = word_dict\n",
    "\n",
    "    return lyrics_dict, all_words\n",
    "\n",
    "# Load the data\n",
    "lyrics_dict_idx, all_words = read_lyrics(lyrics_train_path, lyrics_test_path)\n",
    "\n",
    "# Make mappings from words to indices, where idx starts at 1\n",
    "word_to_idx = {word: index+1 for index, word in enumerate(all_words)}\n",
    "index_to_word = {index+1: word for index, word in enumerate(all_words)}\n",
    "\n",
    "# Create a dictionary with words instead of indices\n",
    "lyrics_dict_word = {track_id: {index_to_word[int(id)]: int(freq) for id, freq in word_dict.items()} for track_id, word_dict in lyrics_dict_idx.items()}\n",
    "\n",
    "# Make inversed index\n",
    "def make_inverted_index(lyrics_word_dict: dict) -> dict:\n",
    "    '''\n",
    "    Input: {track_id: {word: count}}\n",
    "    Output: {word: {track_id: count}}\n",
    "    '''\n",
    "    # Initialize an empty list for each word in the vocabulary\n",
    "    inverted_index = {word: {} for word in all_words}\n",
    "    \n",
    "    # Iterate over each track and its corresponding word dictionary\n",
    "    for track_id, word_dict in lyrics_word_dict.items():\n",
    "        # Iterate over each word ID in the word dictionary\n",
    "        for word, count in word_dict.items():\n",
    "            # Get the word corresponding to the word ID and append the track ID\n",
    "            inverted_index[word][track_id] = count\n",
    "    \n",
    "    return inverted_index\n",
    "\n",
    "inverted_index = make_inverted_index(lyrics_dict_word)\n",
    "\n",
    "# Save the data\n",
    "def save_lyrics_inverted_index(lyrics_inverted_index, path='data/lyrics_inverted_word.pkl'):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(lyrics_inverted_index, file)\n",
    "    print(f\"lyrics_inverted_index saved as pickle at {path}\")\n",
    "\n",
    "# Save the inverted index\n",
    "save_lyrics_inverted_index(inverted_index)\n",
    "\n",
    "# Load the data\n",
    "with open(lyrics_inverted_index_path, 'rb') as file:\n",
    "    inverted_index = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 5000\n",
      "Number of tracks: 237662\n",
      "First 5 words: ['i', 'the', 'you', 'to', 'and']\n",
      "One example of the index dictionary\n",
      "\tTRAAAAV128F421A322: {1: 6, 2: 4, 3: 2, 4: 2, 5: 5, 6: 3, 7: 1, 8: 1, 11: 1, 12: 2, 13: 3, 14: 1, 15: 1, 18: 2, 19: 2, 20: 2, 21: 2, 23: 4, 25: 1, 26: 2, 28: 1, 30: 1, 36: 2, 42: 1, 45: 1, 54: 2, 56: 1, 57: 1, 68: 1, 99: 1, 192: 2, 249: 1, 264: 1, 356: 1, 389: 1, 561: 1, 639: 1, 656: 1, 687: 1, 761: 1, 773: 1, 804: 1, 869: 2, 914: 1, 1035: 1, 1156: 1, 1221: 1, 1287: 1, 1364: 1, 1407: 1, 1533: 2, 1857: 1, 2096: 1, 2117: 1, 2482: 2, 2548: 1, 2705: 1, 2723: 1, 2868: 2, 2992: 2, 3455: 1, 3717: 1, 3851: 1, 4322: 1, 4382: 1, 4613: 1, 4713: 1, 4906: 1}\n",
      "One example of the word dictionary\n",
      "\tTRAAAAV128F421A322: {'i': 6, 'the': 4, 'you': 2, 'to': 2, 'and': 5, 'a': 3, 'me': 1, 'it': 1, 'my': 1, 'is': 2, 'of': 3, 'your': 1, 'that': 1, 'are': 2, 'we': 2, 'am': 2, 'will': 2, 'for': 4, 'be': 1, 'have': 2, 'so': 1, 'this': 1, 'like': 2, 'de': 1, 'up': 1, 'was': 2, 'if': 1, 'got': 1, 'would': 1, 'been': 1, 'these': 2, 'seem': 1, 'someon': 1, 'understand': 1, 'pass': 1, 'river': 1, 'met': 1, 'piec': 1, 'damn': 1, 'worth': 1, 'flesh': 1, 'grace': 1, 'poor': 2, 'somehow': 1, 'ignor': 1, 'passion': 1, 'tide': 1, 'season': 1, 'seed': 1, 'resist': 1, 'order': 2, 'piti': 1, 'fashion': 1, 'grant': 1, 'captur': 2, 'ici': 1, 'soil': 1, 'patienc': 1, 'social': 2, 'highest': 2, 'slice': 1, 'leaf': 1, 'lifeless': 1, 'arrang': 1, 'wilder': 1, 'shark': 1, 'devast': 1, 'element': 1}\n",
      "One example of the inversed index\n",
      "chocol (570 tracks): {'TRAAGNS128E07824BD': 1, 'TRACSGW128F1495A28': 3, 'TRADQTB128F429F85F': 1, 'TRAEOMZ128F429393C': 1, 'TRAGUEL128F92C48CF': 1}\n"
     ]
    }
   ],
   "source": [
    "# SHOW DATA\n",
    "print('Number of words:', len(all_words))\n",
    "print('Number of tracks:', len(lyrics_dict_idx))\n",
    "print('First 5 words:', all_words[:5])\n",
    "print('One example of the index dictionary')\n",
    "for track_id, word_dict in lyrics_dict_idx.items():\n",
    "    print(f\"\\t{track_id}: {word_dict}\")\n",
    "    break\n",
    "print('One example of the word dictionary')\n",
    "for track_id, word_dict in lyrics_dict_word.items():\n",
    "    print(f\"\\t{track_id}: {word_dict}\")\n",
    "    break\n",
    "\n",
    "print('One example of the inversed index')\n",
    "word_example = 'chocol'\n",
    "print(f\"{word_example} ({len(inverted_index[word_example])} tracks):\", {k: v for k, v in list(inverted_index[word_example].items())[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word embeddings, we will use FastText Pretrained Models, which handle out-of-vocabulary (OOV) words using subword information.\n",
    "\n",
    "We will use the english embeddings from fasttext, downloaded from [here](https://fasttext.cc/docs/en/crawl-vectors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "# Info: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "# !pip install fasttext\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "# !pip install PyStemmer\n",
    "\n",
    "# Import word2vec model\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "print(ft.get_dimension())\n",
    "\n",
    "# Use same word preprocessing as match-api\n",
    "import sys\n",
    "sys.path.append('../match-api/')\n",
    "from utils.text_processing import process_text, normalize, tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|██████████| 5000/5000 [39:56<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final save complete. 5000 words processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SAVE A DICTIONARY WITH SIMILAR WORDS FOR ALL 5000 WORDS IN LYRICS\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_lyrics_similarity_dict(all_words, embeddings, save_path='lyrics_similarity_dict.json', batch_size=100):\n",
    "    '''\n",
    "    Create a dictionary with similar tokens to those in the lyrics.\n",
    "    Similar tokens are those with score > 0.7.\n",
    "    Progress is saved every batch_size words.\n",
    "    If interrupted, resumes from the saved file.\n",
    "    '''\n",
    "\n",
    "    # Load existing dictionary if the file exists\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'r', encoding='utf-8') as f:\n",
    "            lyrics_similarity_dict = json.load(f)\n",
    "        processed_words = set(lyrics_similarity_dict.keys())\n",
    "        print(f\"Loaded {len(processed_words)} processed words from {save_path}\")\n",
    "    else:\n",
    "        lyrics_similarity_dict = {}\n",
    "        processed_words = set()\n",
    "\n",
    "    # Get words to process\n",
    "    words_to_process = set(all_words) - processed_words\n",
    "\n",
    "    # Iterate over remaining words with a progress bar\n",
    "    for i, word in enumerate(tqdm(words_to_process, desc=\"Processing words\", initial=len(processed_words), total=len(all_words))):\n",
    "        # Get all words with a similarity score of >0.7\n",
    "        similar_words = {word.lower() for score, word in embeddings.get_nearest_neighbors(word, k=20) if score > 0.7}\n",
    "        extra_tokens = set(normalize(similar_words)) & set(all_words) - {word}\n",
    "\n",
    "        # Add the similar words to the dictionary\n",
    "        lyrics_similarity_dict[word] = list(extra_tokens)  # Convert set to list for JSON compatibility\n",
    "\n",
    "        # Save the dictionary to file every batch_size iterations\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            with open(save_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(lyrics_similarity_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Final save to ensure all data is written\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(lyrics_similarity_dict, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Final save complete. {len(lyrics_similarity_dict)} words processed.\")\n",
    "\n",
    "    return lyrics_similarity_dict\n",
    "\n",
    "lyrics_similarity_dict = create_lyrics_similarity_dict(all_words, ft, save_path='data/lyrics_similarity_dict.json', batch_size=100)\n",
    "\n",
    "# Function to save the lyrics_similarity_dict as a pickle file\n",
    "def save_lyrics_similarity_dict(lyrics_similarity_dict, path='data/lyrics_similarity_dict.pkl'):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(lyrics_similarity_dict, file)\n",
    "    print(f\"lyrics_similarity_dict saved as pickle at {path}\")\n",
    "\n",
    "# Save the lyrics_similarity_dict as a pickle for faster loading\n",
    "save_lyrics_similarity_dict(lyrics_similarity_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

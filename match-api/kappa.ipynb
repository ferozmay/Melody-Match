{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 1]\n",
      " [0 0 3 0]\n",
      " [2 0 0 1]\n",
      " [1 2 0 0]\n",
      " [2 1 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 2 1]\n",
      " [0 0 3 0]\n",
      " [0 0 2 1]\n",
      " [0 2 0 1]\n",
      " [3 0 0 0]\n",
      " [0 0 3 0]\n",
      " [3 0 0 0]\n",
      " [2 0 0 1]\n",
      " [0 3 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 0 1]\n",
      " [1 0 0 2]\n",
      " [0 1 0 2]\n",
      " [0 3 0 0]\n",
      " [1 1 0 1]\n",
      " [1 0 0 2]\n",
      " [0 0 1 2]\n",
      " [1 0 0 2]\n",
      " [0 0 1 2]\n",
      " [0 0 1 2]\n",
      " [0 1 0 2]\n",
      " [0 0 1 2]\n",
      " [0 0 0 3]\n",
      " [1 0 0 2]\n",
      " [0 0 0 3]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 2 1]\n",
      " [0 2 0 1]\n",
      " [0 0 0 3]\n",
      " [0 2 0 1]\n",
      " [0 0 1 2]\n",
      " [1 1 0 1]\n",
      " [1 2 0 0]\n",
      " [2 0 0 1]\n",
      " [1 1 0 1]\n",
      " [2 1 0 0]\n",
      " [1 0 0 2]\n",
      " [0 2 1 0]\n",
      " [0 0 3 0]\n",
      " [2 1 0 0]\n",
      " [0 0 2 1]\n",
      " [0 0 1 2]\n",
      " [0 0 3 0]\n",
      " [0 0 2 1]\n",
      " [2 1 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [1 2 0 0]\n",
      " [0 0 3 0]\n",
      " [2 1 0 0]]\n",
      "0.4154085097161021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters, cohens_kappa\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/FMA_similarity_evaluation.xlsx - Evaluators_main16_joined.csv')\n",
    "\n",
    "df.rename(columns={'Evaluator': 'annotator', 'Track_id': 'track_id'}, inplace=True)\n",
    "\n",
    "#Â get rid of the \"Main\" similarity values\n",
    "\n",
    "df_edited = df[df['Similarity'] != \"Main\"]\n",
    "\n",
    "\n",
    "df_pivoted = df_edited.pivot_table(index=['track_id'], columns='annotator', values='Similarity', aggfunc='first')\n",
    "# Reset the index to move 'track_id' from index to a column\n",
    "df = df_pivoted.reset_index()\n",
    "df.columns.name = None\n",
    "df.drop(columns=['track_id'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.rename(columns={1: 'annotator_1', 2: 'annotator_2', 3:'annotator_3'}, inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Initialize an empty list to store counts for each track\n",
    "contingency_table = []\n",
    "\n",
    "ratings = ['D', 'N', 'VS','S']\n",
    "\n",
    "# Iterate through each row (track) and count the occurrences of each rating\n",
    "for _, row in df_pivoted.iterrows():\n",
    "    track_ratings = row.values\n",
    "    # Count the occurrences of each rating\n",
    "    counts = [sum(track_ratings == rating) for rating in ratings]\n",
    "    contingency_table.append(counts)\n",
    "\n",
    "# Convert the contingency table to a numpy array\n",
    "contingency_array = np.array(contingency_table)\n",
    "\n",
    "print(contingency_array)\n",
    "\n",
    "# Calculate Fleiss' Kappa\n",
    "aggregate_raters(contingency_array, n_cat=4)\n",
    "\n",
    "result = fleiss_kappa(contingency_array)\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
